#!/usr/bin/env python3
"""
è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿä¸»ç¨‹åº
ä½¿ç”¨æœ€æ–°çš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œè‚¡ç¥¨è¶‹åŠ¿é¢„æµ‹

ä½œè€…: Devin AI
ç‰ˆæœ¬: 1.0.0
"""

import argparse
import os
import sys
import yaml
import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Any

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.data_acquisition import get_stock_data
from src.data_preprocessing import preprocess_stock_data
from src.training import train_stock_models
from src.prediction import predict_stock_prices
from src.evaluation import evaluate_predictions

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/stock_prediction.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def load_config(config_path: str = "config.yaml") -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
        logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
        return config
    except Exception as e:
        logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        sys.exit(1)

def setup_directories(config: Dict[str, Any]) -> None:
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        config['paths']['data_dir'],
        config['paths']['models_dir'],
        config['paths']['logs_dir'],
        config['paths']['results_dir']
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        logger.info(f"ç›®å½•å·²åˆ›å»º: {directory}")

def download_data(config: Dict[str, Any]) -> pd.DataFrame:
    """ä¸‹è½½è‚¡ç¥¨æ•°æ®"""
    logger.info("å¼€å§‹ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
    
    symbols = config['data']['symbols']
    period = config['data']['period']
    source = config['data'].get('source', 'yahoo')
    
    tushare_token = config.get('api_keys', {}).get('tushare_token', '')
    alpha_vantage_key = config.get('api_keys', {}).get('alpha_vantage_key', '')
    
    try:
        logger.info(f"ä½¿ç”¨æ•°æ®æº: {source}")
        
        data = get_stock_data(
            symbols, 
            period=period, 
            source=source,
            tushare_token=tushare_token,
            alpha_vantage_key=alpha_vantage_key
        )
        
        if data.empty:
            logger.error("æœªèƒ½è·å–åˆ°è‚¡ç¥¨æ•°æ®")
            logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº...")
            
            backup_sources = ['tushare', 'yahoo', 'alpha_vantage']
            backup_sources = [s for s in backup_sources if s != source]
            
            for backup_source in backup_sources:
                logger.info(f"å°è¯•å¤‡ç”¨æ•°æ®æº: {backup_source}")
                data = get_stock_data(
                    symbols, 
                    period=period, 
                    source=backup_source,
                    tushare_token=tushare_token,
                    alpha_vantage_key=alpha_vantage_key
                )
                if not data.empty:
                    logger.info(f"æˆåŠŸä½¿ç”¨å¤‡ç”¨æ•°æ®æº {backup_source} è·å–æ•°æ®")
                    break
            
            if data.empty:
                logger.error("æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–æ•°æ®")
                sys.exit(1)
        
        data_path = os.path.join(config['paths']['data_dir'], 'stock_data.csv')
        data.to_csv(data_path)
        
        logger.info(f"è‚¡ç¥¨æ•°æ®ä¸‹è½½å®Œæˆï¼Œå…± {len(data)} æ¡è®°å½•")
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {data_path}")
        
        return data
        
    except Exception as e:
        logger.error(f"æ•°æ®ä¸‹è½½å¤±è´¥: {str(e)}")
        sys.exit(1)

def train_models(data: pd.DataFrame, config: Dict[str, Any]) -> Dict[str, Any]:
    """è®­ç»ƒæ¨¡å‹"""
    logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹è®­ç»ƒ...")
    
    try:
        X_train, y_train, X_val, y_val, X_test, y_test, preprocessor = preprocess_stock_data(data, config)
        
        logger.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆ:")
        logger.info(f"  è®­ç»ƒé›†: {X_train.shape}")
        logger.info(f"  éªŒè¯é›†: {X_val.shape}")
        logger.info(f"  æµ‹è¯•é›†: {X_test.shape}")
        
        results = train_stock_models(X_train, y_train, X_val, y_val, X_test, y_test, preprocessor)
        
        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        return results
        
    except Exception as e:
        logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
        sys.exit(1)

def evaluate_models(results: Dict[str, Any], config: Dict[str, Any]) -> None:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    logger.info("å¼€å§‹æ¨¡å‹è¯„ä¼°...")
    
    try:
        y_true = results['test_actuals']
        
        if 'all_predictions' in results:
            predictions_dict = results['all_predictions']
        else:
            predictions_dict = {}
            for model_name in ['haelt', 'lstm', 'transformer']:
                if model_name in results['models']:
                    predictions_dict[model_name] = results['ensemble_predictions']
            predictions_dict['ensemble'] = results['ensemble_predictions']
        
        evaluation_results = evaluate_predictions(
            y_true,
            predictions_dict,
            save_plots=True,
            plots_path=os.path.join(config['paths']['results_dir'], 'evaluation_plots.png')
        )
        
        report_path = os.path.join(config['paths']['results_dir'], 'evaluation_report.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(evaluation_results['evaluation_report'])
        
        logger.info("æ¨¡å‹è¯„ä¼°å®Œæˆ")
        logger.info(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        print("\n=== æ¨¡å‹æ€§èƒ½æ€»ç»“ ===")
        print(evaluation_results['comparison_table'])
        print(f"\næœ€ä½³æ¨¡å‹: {evaluation_results['best_model']}")
        
    except Exception as e:
        logger.error(f"æ¨¡å‹è¯„ä¼°å¤±è´¥: {str(e)}")

def predict_future(data: pd.DataFrame, config: Dict[str, Any], days_ahead: int = 5) -> None:
    """é¢„æµ‹æœªæ¥è‚¡ä»·"""
    logger.info(f"å¼€å§‹é¢„æµ‹æœªæ¥ {days_ahead} å¤©çš„è‚¡ä»·...")
    
    try:
        prediction_results = predict_stock_prices(
            data,
            config_path="config.yaml",
            models_dir=config['paths']['models_dir'],
            days_ahead=days_ahead
        )
        
        future_predictions = prediction_results['future_predictions']
        prediction_dates = prediction_results['prediction_dates']
        
        print(f"\n=== æœªæ¥ {days_ahead} å¤©è‚¡ä»·é¢„æµ‹ ===")
        for i, (date, price) in enumerate(zip(prediction_dates, future_predictions)):
            print(f"{date.strftime('%Y-%m-%d')}: ${price:.2f}")
        
        predictions_path = os.path.join(config['paths']['results_dir'], 'future_predictions.csv')
        predictions_df = pd.DataFrame({
            'date': prediction_dates,
            'predicted_price': future_predictions
        })
        predictions_df.to_csv(predictions_path, index=False)
        
        logger.info(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {predictions_path}")
        
    except Exception as e:
        logger.error(f"æœªæ¥é¢„æµ‹å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', choices=['train', 'predict', 'evaluate', 'all', 'demo'], 
                       default='all', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--symbols', nargs='+', help='è‚¡ç¥¨ä»£ç åˆ—è¡¨')
    parser.add_argument('--days', type=int, default=5, help='é¢„æµ‹å¤©æ•°')
    parser.add_argument('--data-file', help='ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("=== è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ ===")
    print("ä½¿ç”¨æœ€æ–°çš„æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œè‚¡ç¥¨è¶‹åŠ¿é¢„æµ‹")
    print("æ”¯æŒçš„æ¨¡å‹: HAELT, LSTM, Transformer, Ensemble")
    print()
    
    config = load_config(args.config)
    setup_directories(config)
    
    if args.symbols:
        config['data']['symbols'] = args.symbols
    
    if args.mode == 'demo':
        print("ğŸš€ è¿è¡Œæ¼”ç¤ºæ¨¡å¼ - å®Œæ•´è‚¡ç¥¨é¢„æµ‹æµç¨‹")
        args.mode = 'all'  # demoæ¨¡å¼ç­‰åŒäºallæ¨¡å¼
    
    if args.data_file and os.path.exists(args.data_file):
        logger.info(f"ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶: {args.data_file}")
        data = pd.read_csv(args.data_file, index_col=0, parse_dates=True)
    else:
        data = download_data(config)
    
    if args.mode in ['train', 'all']:
        results = train_models(data, config)
        
        if args.mode in ['evaluate', 'all']:
            evaluate_models(results, config)
    
    if args.mode in ['predict', 'all']:
        predict_future(data, config, args.days)
    
    print("\n=== ç¨‹åºæ‰§è¡Œå®Œæˆ ===")
    print("è¯·æŸ¥çœ‹ results/ ç›®å½•è·å–è¯¦ç»†ç»“æœ")

if __name__ == "__main__":
    main()
