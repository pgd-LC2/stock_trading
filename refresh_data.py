#!/usr/bin/env python3
"""
è‚¡ç¥¨æ•°æ®åˆ·æ–°å·¥å…·
Stock Data Refresh Tool

ç”¨äºåˆ·æ–°æœ¬åœ°è‚¡ç¥¨æ•°æ®åº“ï¼Œè·å–æœ€æ–°çš„å¸‚åœºæ•°æ®
Used to refresh local stock database with latest market data
"""

import os
import sys
import shutil
import argparse
import pandas as pd
from datetime import datetime, timedelta
import logging

sys.path.append('src')

from src.data_acquisition import StockDataAcquisition, get_stock_data

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def print_banner():
    """æ˜¾ç¤ºåˆ·æ–°å·¥å…·æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    è‚¡ç¥¨æ•°æ®åˆ·æ–°å·¥å…·                            â•‘
â•‘                  Stock Data Refresh Tool                     â•‘
â•‘                                                              â•‘
â•‘  ğŸ”„ åˆ·æ–°æœ¬åœ°è‚¡ç¥¨æ•°æ®åº“                                         â•‘
â•‘  ğŸ“Š è·å–æœ€æ–°å¸‚åœºæ•°æ®                                           â•‘
â•‘  ğŸ—‘ï¸  æ¸…é™¤è¿‡æœŸç¼“å­˜                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

def clear_cache():
    """æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®"""
    print("ğŸ—‘ï¸  æ¸…é™¤ç¼“å­˜æ•°æ®...")
    
    cache_dirs = ['data/', 'models/', 'results/', 'logs/']
    
    for cache_dir in cache_dirs:
        if os.path.exists(cache_dir):
            try:
                for filename in os.listdir(cache_dir):
                    file_path = os.path.join(cache_dir, filename)
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                        print(f"  âœ… åˆ é™¤æ–‡ä»¶: {file_path}")
                    elif os.path.isdir(file_path):
                        shutil.rmtree(file_path)
                        print(f"  âœ… åˆ é™¤ç›®å½•: {file_path}")
                        
            except Exception as e:
                print(f"  âŒ æ¸…é™¤ {cache_dir} å¤±è´¥: {e}")
        else:
            print(f"  â„¹ï¸  ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
    
    print("âœ… ç¼“å­˜æ¸…é™¤å®Œæˆ")

def check_data_freshness(data_file: str) -> bool:
    """æ£€æŸ¥æ•°æ®æ˜¯å¦æ–°é²œï¼ˆ24å°æ—¶å†…ï¼‰"""
    if not os.path.exists(data_file):
        return False
    
    file_time = datetime.fromtimestamp(os.path.getmtime(data_file))
    current_time = datetime.now()
    
    if current_time - file_time > timedelta(hours=24):
        return False
    
    return True

def refresh_stock_data(symbols: list, period: str = "2y", force: bool = False):
    """åˆ·æ–°è‚¡ç¥¨æ•°æ®"""
    print(f"ğŸ“Š åˆ·æ–°è‚¡ç¥¨æ•°æ®: {symbols}")
    
    data_dir = "data"
    os.makedirs(data_dir, exist_ok=True)
    
    for symbol in symbols:
        data_file = os.path.join(data_dir, f"{symbol}_data.csv")
        
        if not force and check_data_freshness(data_file):
            print(f"  â„¹ï¸  {symbol} æ•°æ®è¾ƒæ–°ï¼Œè·³è¿‡åˆ·æ–°")
            continue
        
        print(f"  ğŸ”„ æ­£åœ¨åˆ·æ–° {symbol} æ•°æ®...")
        
        try:
            acquisition = StockDataAcquisition()
            data = acquisition.fetch_yahoo_data(symbol, period=period)
            
            if not data.empty:
                acquisition.save_data(data, data_file)
                print(f"  âœ… {symbol} æ•°æ®åˆ·æ–°æˆåŠŸï¼Œå…± {len(data)} æ¡è®°å½•")
                
                start_date = data.index.min().strftime('%Y-%m-%d')
                end_date = data.index.max().strftime('%Y-%m-%d')
                latest_price = data['close'].iloc[-1]
                print(f"     æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
                print(f"     æœ€æ–°ä»·æ ¼: ${latest_price:.2f}")
            else:
                print(f"  âŒ {symbol} æ•°æ®è·å–å¤±è´¥")
                
        except Exception as e:
            print(f"  âŒ {symbol} åˆ·æ–°å¤±è´¥: {e}")

def refresh_all_data(force: bool = False):
    """åˆ·æ–°æ‰€æœ‰å¸¸ç”¨è‚¡ç¥¨æ•°æ®"""
    print("ğŸ“ˆ åˆ·æ–°æ‰€æœ‰å¸¸ç”¨è‚¡ç¥¨æ•°æ®...")
    
    popular_symbols = [
        'AAPL', 'TSLA', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA',
        'BABA', 'JD', 'PDD', 'BIDU', 'NIO',
        'SPY', 'QQQ', 'BTC-USD', 'ETH-USD'
    ]
    
    refresh_stock_data(popular_symbols, force=force)

def update_existing_data():
    """æ›´æ–°ç°æœ‰æ•°æ®æ–‡ä»¶"""
    print("ğŸ”„ æ›´æ–°ç°æœ‰æ•°æ®æ–‡ä»¶...")
    
    data_dir = "data"
    if not os.path.exists(data_dir):
        print("  â„¹ï¸  æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°")
        return
    
    existing_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    
    if not existing_files:
        print("  â„¹ï¸  æœªæ‰¾åˆ°ç°æœ‰æ•°æ®æ–‡ä»¶")
        return
    
    print(f"  æ‰¾åˆ° {len(existing_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    for file in existing_files:
        file_path = os.path.join(data_dir, file)
        
        try:
            existing_data = pd.read_csv(file_path, index_col=0, parse_dates=True)
            
            if 'symbol' in existing_data.columns:
                symbol = existing_data['symbol'].iloc[0]
                
                print(f"  ğŸ”„ æ›´æ–° {symbol} æ•°æ®...")
                
                acquisition = StockDataAcquisition()
                new_data = acquisition.fetch_yahoo_data(symbol, period="1mo")
                
                if not new_data.empty:
                    combined_data = pd.concat([existing_data, new_data])
                    combined_data = combined_data[~combined_data.index.duplicated(keep='last')]
                    combined_data = combined_data.sort_index()
                    
                    combined_data.to_csv(file_path)
                    print(f"    âœ… {symbol} æ•°æ®æ›´æ–°å®Œæˆ")
                else:
                    print(f"    âŒ {symbol} æ–°æ•°æ®è·å–å¤±è´¥")
            else:
                print(f"    âš ï¸  {file} æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡")
                
        except Exception as e:
            print(f"    âŒ æ›´æ–° {file} å¤±è´¥: {e}")

def show_data_status():
    """æ˜¾ç¤ºæ•°æ®çŠ¶æ€"""
    print("ğŸ“Š æ•°æ®çŠ¶æ€æ£€æŸ¥...")
    
    data_dir = "data"
    if not os.path.exists(data_dir):
        print("  âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return
    
    files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    
    if not files:
        print("  â„¹ï¸  æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return
    
    print(f"  ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    print(f"  ğŸ“„ æ–‡ä»¶æ•°é‡: {len(files)}")
    print()
    
    for file in files:
        file_path = os.path.join(data_dir, file)
        
        try:
            file_size = os.path.getsize(file_path) / 1024  # KB
            file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            age = datetime.now() - file_time
            
            data = pd.read_csv(file_path, index_col=0, parse_dates=True)
            symbol = data['symbol'].iloc[0] if 'symbol' in data.columns else 'Unknown'
            
            status = "ğŸŸ¢ æ–°é²œ" if age.total_seconds() < 86400 else "ğŸŸ¡ è¾ƒæ—§"
            
            print(f"  {status} {symbol:6} | {len(data):5}æ¡ | {file_size:6.1f}KB | {file_time.strftime('%Y-%m-%d %H:%M')}")
            
        except Exception as e:
            print(f"  âŒ {file:20} | è¯»å–å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨æ•°æ®åˆ·æ–°å·¥å…·')
    parser.add_argument('--mode', choices=['refresh', 'clear', 'update', 'status', 'all'], 
                       default='refresh', help='æ“ä½œæ¨¡å¼')
    parser.add_argument('--symbols', nargs='+', help='æŒ‡å®šè‚¡ç¥¨ä»£ç ')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ•°æ®')
    parser.add_argument('--period', default='2y', help='æ•°æ®æ—¶é—´èŒƒå›´')
    
    args = parser.parse_args()
    
    print_banner()
    
    if args.mode == 'clear':
        clear_cache()
        
    elif args.mode == 'refresh':
        if args.symbols:
            refresh_stock_data(args.symbols, period=args.period, force=args.force)
        else:
            refresh_all_data(force=args.force)
            
    elif args.mode == 'update':
        update_existing_data()
        
    elif args.mode == 'status':
        show_data_status()
        
    elif args.mode == 'all':
        print("ğŸš€ æ‰§è¡Œå®Œæ•´åˆ·æ–°æµç¨‹...")
        clear_cache()
        refresh_all_data(force=True)
        show_data_status()
    
    print("\nâœ… æ•°æ®åˆ·æ–°å®Œæˆï¼")
    print("ğŸ’¡ æç¤º: è¿è¡Œ 'python refresh_data.py --mode status' æŸ¥çœ‹æ•°æ®çŠ¶æ€")

if __name__ == "__main__":
    main()
